{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Index Constituents from Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page: 1\n",
      "Scraping page: 2\n",
      "Scraping page: 3\n",
      "Scraping page: 4\n",
      "Scraping page: 5\n",
      "['III.L', 'ADML.L', 'AAL.L', 'ANTO.L', 'AHT.L', 'ABF.L', 'AZN.L', 'AUTOA.L', 'AV.L', 'BAES.L', 'BARC.L', 'BDEV.L', 'BKGH.L', 'BHPB.L', 'BP.L', 'BATS.L', 'BLND.L', 'BT.L', 'BNZL.L', 'BRBY.L', 'CCL.L', 'CNA.L', 'CCH.L', 'CPG.L', 'CRH.L', 'CRDA.L', 'DCC.L', 'DGE.L', 'DLGD.L', 'TUIT.L', 'SMDS.L', 'EZJ.L', 'EVRE.L', 'EXPN.L', 'FERG.L', 'FRES.L', 'GSK.L', 'GLEN.L', 'HLMA.L', 'HRGV.L', 'HIK.L', 'HSX.L', 'HSBA.L', 'IMB.L', 'INF.L', 'IHG.L', 'ICAG.L', 'ITRK.L', 'ITV.L', 'SBRY.L', 'JMAT.L', 'JE.L', 'KGF.L', 'LAND.L', 'LGEN.L', 'LLOY.L', 'LSE.L', 'MKS.L', 'MCRO.L', 'MNDI.L', 'NG.L', 'MRON.L', 'NXT.L', 'NMC.L', 'OCDO.L', 'FLTRF.L', 'PSON.L', 'PSN.L', 'PHNX.L', 'PRU.L', 'RB.L', 'REL.L', 'RTO.L', 'RMV.L', 'RIO.L', 'RR.L', 'RBS.L', 'RDSa.L', 'RDSb.L', 'RSA.L', 'SDR.L', 'SMT.L', 'SGRO.L', 'SVT.L', 'SN.L', 'SMIN.L', 'SKG.L', 'SPX.L', 'SSE.L', 'SJP.L', 'STAN.L', 'SLA.L', 'TW.L', 'TSCO.L', 'SGE.L', 'ULVR.L', 'UU.L', 'VOD.L', 'WTB.L', 'MRW.L', 'WPP.L']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "index = 'https://www.reuters.com/finance/markets/index/' + '.FTSE'  #'.SPX'\n",
    "\n",
    "page = 1\n",
    "regex = re.compile(r'/finance/stocks/overview/.*')\n",
    "symbols = []\n",
    "\n",
    "while True:\n",
    "  print('Scraping page:', page)\n",
    "  params = params={'sortBy': '', 'sortDir' :'', 'pn': page}\n",
    "  html = session.get(index, params=params).text\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  pagenav = soup.find(class_='pageNavigation')\n",
    "  if not pagenav:\n",
    "    break\n",
    "  companies = pagenav.find_next('table', class_='dataTable')\n",
    "  for link in companies.find_all('a', href=regex):\n",
    "    symbols.append(link.get('href').split('/')[-1])\n",
    "  page += 1\n",
    "\n",
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp500_symbols = symbols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snp500_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftse_symbols = symbols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftse_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Company Name and Description from Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping symbol: III.L\n",
      "Scraping symbol: ADML.L\n",
      "Scraping symbol: AAL.L\n",
      "Scraping symbol: ANTO.L\n",
      "Scraping symbol: AHT.L\n",
      "Scraping symbol: ABF.L\n",
      "Scraping symbol: AZN.L\n",
      "Scraping symbol: AUTOA.L\n",
      "Scraping symbol: AV.L\n",
      "Scraping symbol: BAES.L\n",
      "Scraping symbol: BARC.L\n",
      "Scraping symbol: BDEV.L\n",
      "Scraping symbol: BKGH.L\n",
      "Scraping symbol: BHPB.L\n",
      "Scraping symbol: BP.L\n",
      "Scraping symbol: BATS.L\n",
      "Scraping symbol: BLND.L\n",
      "Scraping symbol: BT.L\n",
      "Scraping symbol: BNZL.L\n",
      "Scraping symbol: BRBY.L\n",
      "Scraping symbol: CCL.L\n",
      "Scraping symbol: CNA.L\n",
      "Scraping symbol: CCH.L\n",
      "Scraping symbol: CPG.L\n",
      "Scraping symbol: CRH.L\n",
      "Scraping symbol: CRDA.L\n",
      "Scraping symbol: DCC.L\n",
      "Scraping symbol: DGE.L\n",
      "Scraping symbol: DLGD.L\n",
      "Scraping symbol: TUIT.L\n",
      "Scraping symbol: SMDS.L\n",
      "Scraping symbol: EZJ.L\n",
      "Scraping symbol: EVRE.L\n",
      "Scraping symbol: EXPN.L\n",
      "Scraping symbol: FERG.L\n",
      "Scraping symbol: FRES.L\n",
      "Scraping symbol: GSK.L\n",
      "Scraping symbol: GLEN.L\n",
      "Scraping symbol: HLMA.L\n",
      "Scraping symbol: HRGV.L\n",
      "Scraping symbol: HIK.L\n",
      "Scraping symbol: HSX.L\n",
      "Scraping symbol: HSBA.L\n",
      "Scraping symbol: IMB.L\n",
      "Scraping symbol: INF.L\n",
      "Scraping symbol: IHG.L\n",
      "Scraping symbol: ICAG.L\n",
      "Scraping symbol: ITRK.L\n",
      "Scraping symbol: ITV.L\n",
      "Scraping symbol: SBRY.L\n",
      "Scraping symbol: JMAT.L\n",
      "Scraping symbol: JE.L\n",
      "Scraping symbol: KGF.L\n",
      "Scraping symbol: LAND.L\n",
      "Scraping symbol: LGEN.L\n",
      "Scraping symbol: LLOY.L\n",
      "Scraping symbol: LSE.L\n",
      "Scraping symbol: MKS.L\n",
      "Scraping symbol: MCRO.L\n",
      "Scraping symbol: MNDI.L\n",
      "Scraping symbol: NG.L\n",
      "Scraping symbol: MRON.L\n",
      "Scraping symbol: NXT.L\n",
      "Scraping symbol: NMC.L\n",
      "Scraping symbol: OCDO.L\n",
      "Scraping symbol: FLTRF.L\n",
      "Scraping symbol: PSON.L\n",
      "Scraping symbol: PSN.L\n",
      "Scraping symbol: PHNX.L\n",
      "Scraping symbol: PRU.L\n",
      "Scraping symbol: RB.L\n",
      "Scraping symbol: REL.L\n",
      "Scraping symbol: RTO.L\n",
      "Scraping symbol: RMV.L\n",
      "Scraping symbol: RIO.L\n",
      "Scraping symbol: RR.L\n",
      "Scraping symbol: RBS.L\n",
      "Scraping symbol: RDSa.L\n",
      "Scraping symbol: RDSb.L\n",
      "Scraping symbol: RSA.L\n",
      "Scraping symbol: SDR.L\n",
      "Scraping symbol: SMT.L\n",
      "Scraping symbol: SGRO.L\n",
      "Scraping symbol: SVT.L\n",
      "Scraping symbol: SN.L\n",
      "Scraping symbol: SMIN.L\n",
      "Scraping symbol: SKG.L\n",
      "Scraping symbol: SPX.L\n",
      "Scraping symbol: SSE.L\n",
      "Scraping symbol: SJP.L\n",
      "Scraping symbol: STAN.L\n",
      "Scraping symbol: SLA.L\n",
      "Scraping symbol: TW.L\n",
      "Scraping symbol: TSCO.L\n",
      "Scraping symbol: SGE.L\n",
      "Scraping symbol: ULVR.L\n",
      "Scraping symbol: UU.L\n",
      "Scraping symbol: VOD.L\n",
      "Scraping symbol: WTB.L\n",
      "Scraping symbol: MRW.L\n",
      "Scraping symbol: WPP.L\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "\n",
    "symbols = ftse_symbols#snp500_symbols\n",
    "nm_run='FTSE'#'SnP500'\n",
    "\n",
    "#if df_store:\n",
    "#    print('Continue store')\n",
    "#else:\n",
    "df_store=pd.DataFrame([], columns=['symbol','Company1','Company2','Description'])\n",
    "\n",
    "profile = 'https://www.reuters.com/finance/stocks/company-profile/{symbol}'\n",
    "\n",
    "for symbol in symbols:\n",
    "    if symbol not in list(df_store.symbol):\n",
    "        print('Scraping symbol:', symbol)\n",
    "        html = session.get(profile.format(symbol=symbol)).text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            comp_nm1=soup.find_all('h1')[0].getText().split('Profile: ')[1].split(' (')[0]\n",
    "        except:\n",
    "            comp_nm1=''\n",
    "\n",
    "        try: \n",
    "            comp_nm2=soup.find_all('title')[0].getText().split(' (')[0]\n",
    "        except:\n",
    "            comp_nm2=''\n",
    "\n",
    "        try:\n",
    "            desc=[soup.find_all('p')[idx].getText() \n",
    "                  for idx in range(len(soup.find_all('p'))) \n",
    "                  if (soup.find_all('p')[idx].getText() !='')\n",
    "                 ]\n",
    "        except:\n",
    "            desc=''\n",
    "        df_new=pd.DataFrame([[symbol,comp_nm1,comp_nm2,desc]], columns=['symbol','Company1','Company2','Description'])\n",
    "        df_store=df_store.append(df_new,ignore_index=True)\n",
    "\n",
    "\n",
    "df_store.to_csv(nm_run + '_comp_nm&desc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Google Knowledge Graph for all Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3i Group PLC: 3i (899.105042)\n",
      "Admiral Group PLC: Admiral Group (358.871979)\n",
      "Anglo American PLC: Anglo American plc (770.969299)\n",
      "Antofagasta PLC: Antofagasta PLC (432.961853)\n",
      "Ashtead Group PLC: Ashtead Group (416.07135)\n",
      "Associated British Foods PLC: Associated British Foods (493.49881)\n",
      "AstraZeneca PLC: AstraZeneca (666.81842)\n",
      "Auto Trader Group PLC: Fidelity European Values (76.299149)\n",
      "Aviva PLC\n",
      "BAE Systems PLC: BAE Systems (1097.216553)\n",
      "Barclays PLC: Barclays (946.037292)\n",
      "Barratt Developments PLC: Wilson Bowden (14.722092)\n",
      "Berkeley Group Holdings PLC: The Berkeley Group Holdings (872.668335)\n",
      "BHP Group PLC\n",
      "BP PLC: BP (1033.500366)\n",
      "British American Tobacco PLC: British American Tobacco (1158.899536)\n",
      "British Land Company PLC: British Land (775.982849)\n",
      "BT Group PLC: BT Group (950.00531)\n",
      "Bunzl plc: Bunzl (314.053253)\n",
      "Burberry Group PLC: Burberry (852.833557)\n",
      "Carnival PLC: Carnival Corporation &amp; plc (475.00708)\n",
      "Centrica PLC: Centrica (514.320557)\n",
      "Coca Cola HBC AG: Coca-Cola Hellenic Bottling Company (475.211334)\n",
      "Compass Group PLC: Compass Group (747.966858)\n",
      "CRH PLC: CRH plc (511.873535)\n",
      "Croda International PLC: Croda International (349.959717)\n",
      "DCC PLC: DCC plc (429.418274)\n",
      "Diageo PLC: Diageo (811.847595)\n",
      "Direct Line Insurance Group PLC: Churchill Insurance (30.133696)\n",
      "TUI AG: TUI Group (472.186462)\n",
      "DS Smith PLC: DS Smith (372.968781)\n",
      "Easyjet PLC: easyJet (513.367004)\n",
      "EVRAZ plc: Evraz (305.969849)\n",
      "Experian PLC: Experian PLC (632.793152)\n",
      "Ferguson PLC: Ferguson plc (493.155762)\n",
      "Fresnillo PLC: Fresnillo plc (437.244659)\n",
      "GlaxoSmithKline PLC: GlaxoSmithKline (795.936279)\n",
      "Glencore PLC: Glencore (594.310852)\n",
      "Halma PLC: Halma plc (436.3013)\n",
      "Hargreaves Lansdown PLC: Hargreaves Lansdown (383.623169)\n",
      "Hikma Pharmaceuticals PLC: Hikma Pharmaceuticals (366.287476)\n",
      "Hiscox Ltd: Hiscox (351.310883)\n",
      "HSBC Holdings PLC: HSBC (1617.023071)\n",
      "Imperial Brands PLC: Imperial Brands (511.533783)\n",
      "Informa PLC: Informa (736.392883)\n",
      "InterContinental Hotels Group PLC: InterContinental Hotels Group (866.205383)\n",
      "International Consolidated Airlines Group SA\n",
      "Intertek Group PLC: Intertek (824.110535)\n",
      "ITV PLC: ITV (581.604309)\n",
      "J Sainsbury PLC: Sainsbury's (1293.032349)\n",
      "Johnson Matthey PLC: Johnson Matthey (473.820465)\n",
      "Just Eat PLC: Just Eat (733.118103)\n",
      "Kingfisher PLC: Kingfisher plc (497.770447)\n",
      "Land Securities Group PLC\n",
      "Legal & General Group PLC: Legal &amp; General (1081.279785)\n",
      "Lloyds Banking Group PLC: Lloyds Banking Group (578.304382)\n",
      "London Stock Exchange Group PLC: London Stock Exchange Group (746.740051)\n",
      "Marks and Spencer Group PLC: Marks &amp; Spencer (1065.22876)\n",
      "Micro Focus International PLC: Micro Focus (579.821716)\n",
      "Mondi PLC\n",
      "National Grid PLC: National Grid plc (886.4953)\n",
      "Melrose Industries PLC: Melrose Industries (335.05069)\n",
      "Next PLC: Next plc (758.108826)\n",
      "NMC Health PLC: Informa (85.433952)\n",
      "Ocado Group PLC\n",
      "Flutter Entertainment PLC: Tesco PLC (110.810417)\n",
      "Pearson PLC: Pearson (677.861206)\n",
      "Persimmon PLC: Persimmon plc (571.441528)\n",
      "Phoenix Group Holdings PLC\n",
      "Prudential PLC: Prudential (514.330566)\n",
      "Reckitt Benckiser Group PLC: Reckitt Benckiser (764.243042)\n",
      "Relx PLC: RELX (95.078239)\n",
      "Rentokil Initial PLC: Rentokil Initial (104.855179)\n",
      "Rightmove PLC: Rightmove (627.499023)\n",
      "Rio Tinto PLC: Rio Tinto (805.168945)\n",
      "Rolls-Royce Holdings PLC: Rolls-Royce Holdings plc (1115.922607)\n",
      "Royal Bank of Scotland Group PLC: Royal Bank of Scotland (1001.523743)\n",
      "Royal Dutch Shell PLC: Royal Dutch Shell (2570.673584)\n",
      "Royal Dutch Shell PLC: Royal Dutch Shell (2570.673584)\n",
      "RSA Insurance Group PLC: RSA Insurance Group (510.496857)\n",
      "Schroders PLC: Schroders (350.824463)\n",
      "Scottish Mortgage Investment Trust PLC\n",
      "SEGRO PLC: Segro (417.534546)\n",
      "Severn Trent PLC: Severn Trent (424.7612)\n",
      "Smith & Nephew PLC: Smith &amp; Nephew (538.290894)\n",
      "Smiths Group PLC: Smiths Group (522.966003)\n",
      "Smurfit Kappa Group PLC: Smurfit Kappa Group (476.994507)\n",
      "Spirax-Sarco Engineering PLC: Spirax-Sarco Engineering (405.293671)\n",
      "SSE PLC: SSE plc (602.533386)\n",
      "St. James's Place PLC: St. James's Place plc (824.149536)\n",
      "Standard Chartered PLC: Standard Chartered (1123.325806)\n",
      "Standard Life Aberdeen PLC: Standard Life Aberdeen (561.529358)\n",
      "Taylor Wimpey PLC: Taylor Wimpey (647.310486)\n",
      "Tesco PLC: Tesco PLC (1017.957275)\n",
      "Sage Group PLC: Sage Group (840.419434)\n",
      "Unilever PLC: Unilever (803.169067)\n",
      "United Utilities Group PLC: United Utilities (437.830627)\n",
      "Vodafone Group PLC: Vodafone Group Plc (1752.870972)\n",
      "Whitbread PLC: Whitbread (558.884949)\n",
      "WM Morrison Supermarkets PLC: Morrisons (1382.278931)\n",
      "WPP PLC: WPP plc (566.610779)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import urllib.parse\n",
    "from requests import get\n",
    "import time\n",
    "\n",
    "api_key = 'AIzaSyCflJRjMC5NHSVH8G7cUAr88Xa4rGKXk0o'\n",
    "\n",
    "service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "result_out = []\n",
    "\n",
    "nm_run='FTSE'\n",
    "df_list=pd.read_csv(nm_run+'_comp_nm&desc.csv',index_col=0)\n",
    "\n",
    "for i, comp_nm in enumerate(list(df_list.Company1)):\n",
    "    query = str(comp_nm).lower().replace(\" corp\", \"\").replace(\" inc\", \"\")\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': 10,\n",
    "        'indent': True,\n",
    "        'key': api_key,\n",
    "    }\n",
    "    url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "    try:\n",
    "        response = json.loads(get(url).content)\n",
    "        out=response['itemListElement']\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "        response = json.loads(get(url).content)\n",
    "        out=response['itemListElement']        \n",
    "    try:\n",
    "        print(comp_nm +': ' +out[0]['result']['name'] + ' (' + str(out[0]['resultScore']) + ')')\n",
    "    except:\n",
    "        print(comp_nm)\n",
    "        \n",
    "    result_out=result_out + [{'ticker': df_list.symbol[i],\n",
    "                              'search': comp_nm,\n",
    "                              'result': out}]\n",
    "    #for i in range(len(out)):\n",
    "    #    print(symbol +': ' +out[i]['result']['name'] + ' (' + str(out[i]['resultScore']) + ')')\n",
    "\n",
    "    \n",
    "result_out_2={'key':result_out}\n",
    "with open(nm_run+'_kg_hits.txt', 'w') as f:\n",
    "    json.dump(result_out_2, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OBSERVATIONS KG API\n",
    "# 1. Capitalisation does not seem to influence\n",
    "# 2. Removing 'Comp', 'Inc' from the name seems to increase the number of hits but also the confidence in the hits\n",
    "# e.g. from 16 to 367 for A. O. Smith\n",
    "# 3. 'Co', 'PLC' is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSBC Holdings PLC: HSBC (1616.993896)\n",
      "HSBC Holdings PLC: HSBC Bank Egypt (61.160534)\n",
      "HSBC Holdings PLC: HSBC Expat (59.015228)\n",
      "HSBC Holdings PLC: HSBC Bank Malta (58.643902)\n",
      "HSBC Holdings PLC: HSBC Bank (55.955559)\n",
      "HSBC Holdings PLC: HSBC Saudi Arabia (51.342865)\n",
      "HSBC Holdings PLC: HSBC Private Bank (48.174179)\n",
      "HSBC Holdings PLC: HSBC France (47.603832)\n",
      "HSBC Holdings PLC: HSBC Bank India (45.983315)\n",
      "HSBC Holdings PLC: HSBC Bank USA (45.813698)\n"
     ]
    }
   ],
   "source": [
    "# One off Look-up\n",
    "\n",
    "comp_nm = 'HSBC Holdings PLC'\n",
    "query = str(comp_nm).lower().replace(\" corp\", \"\").replace(\" inc\", \"\")\n",
    "params = {\n",
    "    'query': query,\n",
    "    'limit': 10,\n",
    "    'indent': True,\n",
    "    'key': api_key,\n",
    "}\n",
    "url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "\n",
    "response = json.loads(get(url).content)\n",
    "out=response['itemListElement']\n",
    "\n",
    "for i in range(len(out)):\n",
    "    print(comp_nm +': ' +out[i]['result']['name'] + ' (' + str(out[i]['resultScore']) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Google Results for Organisations only\n",
    "\n",
    "Note option to add subsidiaries which essentially means running through the whole list of google hits and adding everyone who is listed as Organisation/Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nm_run='SnP500'\n",
    "add_subsidiaries = True\n",
    "\n",
    "\n",
    "df_list=pd.read_csv(nm_run + '_comp_nm&desc.csv',index_col=0)\n",
    "with open(nm_run+'_kg_hits.txt') as ff:\n",
    "    result_out = json.load(ff)['key']\n",
    "    \n",
    "    \n",
    "corp_org=['Corporation', 'Organization']\n",
    "col_nm = ['Ticker','Company_Name','KG_ID', 'Entry_Name', 'KG_Desc', 'Comp_URL', 'Wiki_URL', 'KG_nr_hit']\n",
    "full_df=pd.DataFrame([],columns=col_nm)\n",
    "\n",
    "for idx in range(len(result_out)):\n",
    "    for inner_idx in range(len(result_out[idx]['result'])):\n",
    "        \n",
    "        kg_res=result_out[idx]['result'][inner_idx]['result']\n",
    "        if len(list(set(corp_org) - set(kg_res['@type']))) < 2:\n",
    "\n",
    "            new_df=pd.DataFrame(\n",
    "                [[result_out[idx]['ticker'],\n",
    "                  result_out[idx]['search'],\n",
    "                   kg_res.get('@id','')[3:],\n",
    "                   kg_res.get('name',''),\n",
    "                   kg_res.get('description',''),\n",
    "                   kg_res.get('url',''),\n",
    "                   kg_res.get('detailedDescription',{}).get('url',''),\n",
    "                   inner_idx\n",
    "                  ]]\n",
    "                ,columns=col_nm)\n",
    "            full_df=full_df.append(new_df,ignore_index=True)\n",
    "            if add_subsidiaries == False:\n",
    "                break\n",
    "\n",
    "    \n",
    "df_final=pd.merge(df_list,full_df,left_on='symbol',right_on='Ticker')\n",
    "df_final=df_final.drop(['symbol','Company1','Company2'],axis=1)\n",
    "df_final=df_final[['Ticker','Company_Name','Entry_Name','KG_ID', 'KG_Desc', 'Description',\n",
    "          'Comp_URL', 'Wiki_URL', 'KG_nr_hit']]\n",
    "\n",
    "if add_subsidiaries == False:\n",
    "    df_final.to_csv(nm_run+ '_Ticker_to_KG.csv')\n",
    "else:\n",
    "    df_final.to_csv(nm_run+ '_Ticker_to_KG_subsidiaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
