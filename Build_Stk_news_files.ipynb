{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prgs_bar(dt0, idx, runs, scale=20):\n",
    "    import sys\n",
    "\n",
    "    sys.stdout.write('\\r'+str(idx+1) + '/'+str(runs) + ' ' +\n",
    "                     (' ' if idx+1<runs else '') +\n",
    "                     \" Progress {:2.2%}\".format((idx+1) / runs) + ' |' +\n",
    "                     ''.join(['=']*int(((idx+1) / runs)*scale)) + \n",
    "                     ('>' if idx+1<runs else '') +\n",
    "                     ''.join(['-']*int(scale-int(((idx+1) / runs)*scale)-1)) +\n",
    "                     '|ETA: ' + str((runs-idx)*(datetime.datetime.now()-dt0)/(idx+1))[:4] + '/' +\n",
    "                     str((runs)*(datetime.datetime.now()-dt0)/(idx+1))[:4] + \n",
    "                    '           ')\n",
    "    sys.stdout.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def add_to_file(new_dict,file_name):\n",
    "    exists = os.path.isfile(file_name)\n",
    "    \n",
    "    if type(new_dict) != list: new_dict = [new_dict]\n",
    "    \n",
    "    if exists:\n",
    "        with open(file_name) as ff:\n",
    "            json_new = json.load(ff)['key'] \n",
    "        json_new = json_new + new_dict\n",
    "    else:\n",
    "        json_new = new_dict\n",
    "    \n",
    "    json_new2 ={'key':json_new}\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(json_new2, f, ensure_ascii=False)\n",
    "        \n",
    "def load_file(file_name):\n",
    "    exists = os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        with open(file_name) as ff:\n",
    "            json_new = json.load(ff)['key'] \n",
    "    else:\n",
    "        json_new = []\n",
    "    \n",
    "    return json_new\n",
    "\n",
    "def write_file(new_dict,file_name):\n",
    "    if type(new_dict) != list: new_dict = [new_dict]\n",
    "    \n",
    "    json_new2 ={'key':new_dict}\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(json_new2, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Ticker Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>KG_Search</th>\n",
       "      <th>KG_ID</th>\n",
       "      <th>KG_Desc</th>\n",
       "      <th>Description</th>\n",
       "      <th>Comp_URL</th>\n",
       "      <th>Wiki_URL</th>\n",
       "      <th>KG_nr_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>III.L</td>\n",
       "      <td>3i Group PLC</td>\n",
       "      <td>/m/02ht0r</td>\n",
       "      <td>Private equity company</td>\n",
       "      <td>['16 Palace StreetLONDON \\xa0  \\xa0 SW1E 5JD\\n...</td>\n",
       "      <td>http://www.3i.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/3i</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADML.L</td>\n",
       "      <td>Admiral Group PLC</td>\n",
       "      <td>/m/08vfdz</td>\n",
       "      <td>Insurance company</td>\n",
       "      <td>['Ty Admiral, David StreetCARDIFF \\xa0  \\xa0 C...</td>\n",
       "      <td>http://www.admiralgroup.co.uk/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Admiral_Group</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL.L</td>\n",
       "      <td>Anglo American PLC</td>\n",
       "      <td>/m/04vd0h</td>\n",
       "      <td>Mining company</td>\n",
       "      <td>['Anglo American House20 Carlton House Terrace...</td>\n",
       "      <td>http://www.angloamerican.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Anglo_American_plc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANTO.L</td>\n",
       "      <td>Antofagasta PLC</td>\n",
       "      <td>/m/05wxdg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Cleveland HSE, 33 King StreetLONDON \\xa0  \\x...</td>\n",
       "      <td>http://www.antofagasta.co.uk/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Antofagasta_PLC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHT.L</td>\n",
       "      <td>Ashtead Group PLC</td>\n",
       "      <td>/m/08yvj9</td>\n",
       "      <td>Company</td>\n",
       "      <td>['100 CheapsideLONDON \\xa0  \\xa0 EC2V 6DT\\nP: ...</td>\n",
       "      <td>http://www.ashtead-group.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ashtead_Group</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker           KG_Search      KG_ID                 KG_Desc  \\\n",
       "0   III.L        3i Group PLC  /m/02ht0r  Private equity company   \n",
       "1  ADML.L   Admiral Group PLC  /m/08vfdz       Insurance company   \n",
       "2   AAL.L  Anglo American PLC  /m/04vd0h          Mining company   \n",
       "3  ANTO.L     Antofagasta PLC  /m/05wxdg                     NaN   \n",
       "4   AHT.L   Ashtead Group PLC  /m/08yvj9                 Company   \n",
       "\n",
       "                                         Description  \\\n",
       "0  ['16 Palace StreetLONDON \\xa0  \\xa0 SW1E 5JD\\n...   \n",
       "1  ['Ty Admiral, David StreetCARDIFF \\xa0  \\xa0 C...   \n",
       "2  ['Anglo American House20 Carlton House Terrace...   \n",
       "3  ['Cleveland HSE, 33 King StreetLONDON \\xa0  \\x...   \n",
       "4  ['100 CheapsideLONDON \\xa0  \\xa0 EC2V 6DT\\nP: ...   \n",
       "\n",
       "                         Comp_URL  \\\n",
       "0              http://www.3i.com/   \n",
       "1  http://www.admiralgroup.co.uk/   \n",
       "2   http://www.angloamerican.com/   \n",
       "3   http://www.antofagasta.co.uk/   \n",
       "4   http://www.ashtead-group.com/   \n",
       "\n",
       "                                           Wiki_URL  KG_nr_hit  \n",
       "0                  https://en.wikipedia.org/wiki/3i          0  \n",
       "1       https://en.wikipedia.org/wiki/Admiral_Group          0  \n",
       "2  https://en.wikipedia.org/wiki/Anglo_American_plc          0  \n",
       "3     https://en.wikipedia.org/wiki/Antofagasta_PLC          0  \n",
       "4       https://en.wikipedia.org/wiki/Ashtead_Group          0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_list = 'FTSE'\n",
    "\n",
    "tick_df=pd.read_csv('./Ticker_TO_KG_ID_Map/'+stk_list+'_Ticker_to_KG.csv',index_col=0)\n",
    "\n",
    "stk_ticks=list(tick_df.Ticker)\n",
    "stk_kg_id=list(tick_df.KG_ID)\n",
    "stk_name=list(tick_df.KG_Search)\n",
    "tick_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set file lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='./entities/'\n",
    "\n",
    "list_files=['rss_crawl2019-04-26 04-03-25_entities.txt',\n",
    "       'rss_crawl2019-04-25 23-00-26_entities.txt', \n",
    "       'rss_crawl2019-04-10 08-45-38_entities.txt',\n",
    "       'rss_crawl2019-04-13 02-07-56_entities.txt',\n",
    "       'rss_crawl2019-04-23 07-51-54_entities.txt',\n",
    "       'rss_crawl2019-04-20 09-10-00_entities.txt',\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r, d, f in os.walk(path):\n",
    "    list_files=f\n",
    "\n",
    "list_files=list(set(list_files)-{'.DS_Store'})\n",
    "len(list_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Stock Ticker Files\n",
    "\n",
    "The loop reuns through each News file and allocates any news that match a KG ID from a provided list of KG_IDs and a list of files to go through. Any hit against a KG_ID gets written to \n",
    " 1. A file with the full news article in the same format\n",
    " 2. An Index file ending in _idx_ which stores the ids of all matching articles\n",
    "\n",
    "INPUTS:\n",
    " 1. stk_kg_id - List of KG_IDs to search\n",
    " 2. stk_ticks - List of stock tickers\n",
    " 3. list_files - list of files to search through\n",
    " 3. salience_threshold - Minimal relevancy of the the stock to an article\n",
    " \n",
    "BENEFITS:\n",
    "\n",
    "This setup has a few useful benefits\n",
    " 1. Does not rely on keeping track - the index files keep track for you of which news were included so even if a file has been run through twice the news will only exist once\n",
    " 2. Can be flexible in changing the list of stocks or list of news files\n",
    " 3. One can use this for a daily update and a big batch update where the day's file is just dumped here and allocated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Improved Design\n",
    "\n",
    "The current design runs through each news file and for each hit loads the stock and the index file, saves the hit and moves on. This is not efficient as loading and closing the files takes a long time, especially when stock files start to get bigger.\n",
    "\n",
    "Improved Design: \n",
    " 1. Change the index file to be a central index file which is a dictionary by stock ticker and holds all news IDs by Stock ticker to look up presence\n",
    " 2. Per each news file, a small dictionary by stock ticker with matching content from the current file will be added to. \n",
    " 3. When done with a file, the dictionary will allocate all results from the file to news files at one go and store the new version of the index file. News distionary will be reset for the next file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded: rss_crawl2019-04-09 00-24-58.063131_entities.txt\n",
      "100/100  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-13 18-00-18_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-25 23-00-26_entities.txt\n",
      "8450/8450  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-05 13-09-32_entities.txt\n",
      "43/43  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-05 22-30-16_entities.txt\n",
      "294/294  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 16-23-53_entities.txt\n",
      "3600/3600  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-04 231136018255_entities.txt\n",
      "134/134  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-11 22-28-45_entities.txt\n",
      "755/839   Progress 89.99% |=================>--|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-22 08-25-28_entities.txt\n",
      "6800/6800  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-26 04-03-25_entities.txt\n",
      "8477/8477  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-19 13-16-01_entities.txt\n",
      "8726/8800   Progress 99.16% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-24 07-08-31_entities.txt\n",
      "350/350  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-29 0085612_entities.txt\n",
      "4/4  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 010027.315286_entities.txt\n",
      "575/575  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 140722.746408_entities.txt\n",
      "47/47  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-24 21-41-28_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 15-13-08_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-24 00-49-39_entities.txt\n",
      "9921/10000   Progress 99.21% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 01-21-16_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-10 17-26-47_entities.txt\n",
      "9813/10000   Progress 98.13% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-29 000445.054593_entities.txt\n",
      "1000/1018   Progress 98.23% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-03 1951442_entities.txt\n",
      "500/914   Progress 54.70% |==========>---------|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-23 23-09-11_entities.txt\n",
      "3000/3000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-29 00.947101_entities.txt\n",
      "1250/1250  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-05 10-42-45_entities.txt\n",
      "343/343  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-26 220209.918207_entities.txt\n",
      "109/114   Progress 95.61% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-11 01-44-33_entities.txt\n",
      "923/923  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 173830.805708_entities.txt\n",
      "9/9  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 160644.577845_entities.txt\n",
      "185/185  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-25 17-29-10_entities.txt\n",
      "9400/9400  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-13 02-07-56_entities.txt\n",
      "7000/7000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 14-08-57_entities.txt\n",
      "1600/1600  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-11 13-25-22_entities.txt\n",
      "9666/10000   Progress 96.66% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-20 12-21-05_entities.txt\n",
      "2000/2000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-20 19-05-24_entities.txt\n",
      "9998/10000   Progress 99.98% |===================>|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-09 20-24-37_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-22 00-34-30_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-04 195840189138_entities.txt\n",
      "954/954  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 08-14-36_entities.txt\n",
      "6250/6250  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-26 192945.366840_entities.txt\n",
      "883/883  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-05 15-43-29_entities.txt\n",
      "195/195  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 224607.300145_entities.txt\n",
      "141/141  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-20 13-29-04_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 12-28-35_entities.txt\n",
      "3450/3450  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-25 08-11-10_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-22 18-00-17_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 18-20-27_entities.txt\n",
      "5000/5000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 11-15-08_entities.txt\n",
      "5000/5000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 00-07-39_entities.txt\n",
      "2000/2000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 21-49-21_entities.txt\n",
      "8750/8750  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-02 205174_entities.txt\n",
      "1038/1038  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 130307.329902_entities.txt\n",
      "186/186  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-20 09-10-00_entities.txt\n",
      "5500/5500  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-29 00.774701_entities.txt\n",
      "1249/1249  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-10 08-45-38_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-19 23-49-12_entities.txt\n",
      "3000/3000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-09 01-46-45_entities.txt\n",
      "2000/2000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 15-48-56_entities.txt\n",
      "669/669  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-10 15-24-49_entities.txt\n",
      "2000/2000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-22 12-30-19_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-08 21-55-33_entities.txt\n",
      "903/903  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-24 07-59-16_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 22-54-42_entities.txt\n",
      "5000/5000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-01 2362714_entities.txt\n",
      "1384/1384  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 130645.615731_entities.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/410  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-05 12-31-30_entities.txt\n",
      "177/177  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-19 18-11-00_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-24 18-09-52_entities.txt\n",
      "5200/5200  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-23 17-04-16_entities.txt\n",
      "7450/7450  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 21-08-57_entities.txt\n",
      "6400/6400  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-23 07-51-54_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-03 232220050155_entities.txt\n",
      "118/118  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-03-25 133527.717086_entities.txt\n",
      "35/35  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 08-16-37_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-20 01-30-29_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 19-47-31_entities.txt\n",
      "5000/5000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-23 00-22-20_entities.txt\n",
      "7950/7950  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 01-14-50_entities.txt\n",
      "200/200  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-06 01-22-34_entities.txt\n",
      "54/54  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-09 20-01-59_entities.txt\n",
      "942/942  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-13 07-47-22_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-21 01-25-47_entities.txt\n",
      "10000/10000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-12 03-37-18_entities.txt\n",
      "7050/7050  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-23 21-24-38_entities.txt\n",
      "3000/3000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-11 22-44-38_entities.txt\n",
      "2000/2000  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-19 12-33-11_entities.txt\n",
      "1250/1250  Progress 100.00% |====================|ETA: 0:00/0:00           \n",
      "Loaded: rss_crawl2019-04-14 14-53-25_entities.txt\n",
      "5000/5000  Progress 100.00% |====================|ETA: 0:00/0:00           Saving...\n"
     ]
    }
   ],
   "source": [
    "salience_threshold = 0.005\n",
    "path_store = './stk_news_list/'\n",
    "\n",
    "\n",
    "nr_hits = 0\n",
    "ttl_hits = 0\n",
    "\n",
    "# Create empty dictionaries for indices and news per file\n",
    "# Index dictionary will be loaded with all existing indices\n",
    "dict_idx={}\n",
    "for stk in stk_ticks:\n",
    "    idx_file = load_file(path_store+stk+'_idx.txt')\n",
    "    if len(idx_file) > 0: dict_idx[stk] = idx_file\n",
    "dict_nws={}\n",
    "\n",
    "for file in list_files:\n",
    "    # Open news file\n",
    "    with open(path+file) as ff:\n",
    "        json2 = json.load(ff)['key']\n",
    "    print('\\nLoaded: ' + file)\n",
    "    \n",
    "    dt0 = datetime.datetime.now()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for idx in range(len(json2)):\n",
    "        if len(json2[idx].get('entities',''))>0:\n",
    "            kg_ids_art=[json2[idx]['entities'][loop]['mid'] \n",
    "                        for loop in range(len(json2[idx]['entities']))\n",
    "                        if json2[idx]['entities'][loop].get('salience',0)>salience_threshold]\n",
    "\n",
    "            stk_news_intersect = list(set(stk_kg_id) & set(kg_ids_art))\n",
    "            for stk_kg_itrs in stk_news_intersect:\n",
    "                #print(stk_kg_itrs)\n",
    "                loc_in_list = stk_kg_id.index(stk_kg_itrs)\n",
    "                stk_ticker = stk_ticks[loc_in_list]\n",
    "                \n",
    "\n",
    "                if json2[idx]['id'] not in dict_idx.get(stk_ticker,[]):\n",
    "                    dict_nws[stk_ticker]=dict_nws.get(stk_ticker,[]) + [json2[idx]]\n",
    "                    dict_idx[stk_ticker]=dict_idx.get(stk_ticker,[]) + [json2[idx]['id']]\n",
    "\n",
    "                nr_hits = nr_hits +1\n",
    "        prgs_bar(dt0, idx, len(json2), scale=20)\n",
    "        ttl_hits = ttl_hits + 1\n",
    "    \n",
    "# Save down updated files at the end of the round\n",
    "print('Saving...')\n",
    "for stk in stk_ticks:\n",
    "    #assert(len(dict_idx.get(stk,[])) == len(dict_nws.get(stk,[])))\n",
    "    if len(dict_nws.get(stk,[]))>0:\n",
    "        add_to_file(dict_nws[stk],path_store+stk+'.txt')\n",
    "        write_file(dict_idx[stk],path_store+stk+'_idx.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10296 / 394418\n"
     ]
    }
   ],
   "source": [
    "# SnP: 42612 / 394418\n",
    "# FTSE: 10296 / 394418\n",
    "\n",
    "print(str(nr_hits) + ' / ' + str(ttl_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
